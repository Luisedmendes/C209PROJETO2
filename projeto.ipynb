{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Importação de bibliotecas e carregando vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import moviepy.editor as mpe\n",
    "import numpy as np \n",
    "from moviepy.audio.fx.all import audio_fadeout\n",
    "video = mpe.VideoFileClip(\"2025-06-05-20-16-53.mp4\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Inverter a imagem a cada 20 segundos Dividir o vídeo em blocos de 20 segundos.\n",
    "\n",
    "Utilizar uma função do numpy que  inverte as entradas em cada linha na direção esquerda/direita. Depois uso fl() (uma funcao do MoviePy) para modificar frames usando a função fliF_Frame que criei."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_frame(get_frame, t):\n",
    "    segment = int(t // 20)\n",
    "    frame = get_frame(t)\n",
    "    if segment % 2 == 1:\n",
    "        frame = np.fliplr(frame)\n",
    "    return frame\n",
    "\n",
    "flipped_video = video.fl(lambda gf, t: flip_frame(gf, t))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reduzir volume gradualmente a cada 30s e deixar os últimos 10s em silêncio\n",
    "\n",
    "A função calculate_fade(t, total_duration, fade_duration) gera um fator de volume que é 1 até o tempo fade_start = total_duration - fade_duration.\n",
    "\n",
    "epois desse ponto (fade_zone), o volume decresce linearmente até zero no final do clipe.\n",
    "\n",
    "Na função volume_adjustment, para cada frame de áudio em tempo t, aplica-se esse fator para multiplicar a amplitude do áudio, fazendo o volume ir caindo até o silêncio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fade(t, total_duration, fade_duration=10):\n",
    "    fade_start = total_duration - fade_duration\n",
    "    fade_factor = np.ones_like(t, dtype=float)\n",
    "    \n",
    "    fade_zone = t >= fade_start\n",
    "    linear_fade = 1 - (t[fade_zone] - fade_start) / fade_duration\n",
    "    \n",
    "    fade_factor[fade_zone] = linear_fade ** 2 \n",
    "    \n",
    "    fade_factor = np.clip(fade_factor, 0, 1)\n",
    "    return fade_factor\n",
    "\n",
    "def add_gradual_fadeout(clip):\n",
    "    if clip.audio is None:\n",
    "        print(\"O clipe não possui áudio.\")\n",
    "        return clip\n",
    "    \n",
    "    def volume_adjustment(get_frame, times):\n",
    "        audio_frame = get_frame(times)\n",
    "        times = np.array(times, ndmin=1)\n",
    "        \n",
    "        volume = calculate_fade(times, clip.duration)\n",
    "        \n",
    "        if audio_frame.ndim == 2:\n",
    "            volume = volume[:, np.newaxis]\n",
    "        \n",
    "        return audio_frame * volume\n",
    "\n",
    "    faded_audio = clip.audio.fl(volume_adjustment)\n",
    "    return clip.set_audio(faded_audio)\n",
    "\n",
    "video_fadeout = add_gradual_fadeout(flipped_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Após o primeiro minuto, 60 segundos, fazer um corte para o segundo 80  \n",
    "Por fim, insira os 20 segundos cortados acima no fim do video \n",
    "\n",
    "Usei o método .subclip(inicio, fim) para extrair trechos específicos do vídeo.\n",
    "\n",
    "Usa concatenate_videoclips para juntar esses trechos na ordem desejada.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video video_editado_final.mp4.\n",
      "MoviePy - Writing audio in video_editado_finalTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video video_editado_final.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready video_editado_final.mp4\n"
     ]
    }
   ],
   "source": [
    "start_cut = 60 \n",
    "end_cut = 80   \n",
    "\n",
    "\n",
    "clip_start = video_fadeout.subclip(0, start_cut)\n",
    "\n",
    "clip_cut = video_fadeout.subclip(start_cut, end_cut)\n",
    "\n",
    "clip_end = video_fadeout.subclip(end_cut, video_fadeout.duration)\n",
    "\n",
    "video_sem_corte = mpe.concatenate_videoclips([clip_start, clip_end])\n",
    "\n",
    "video_final = mpe.concatenate_videoclips([video_sem_corte, clip_cut])\n",
    "\n",
    "video_final.write_videofile(\"video_editado_final.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
